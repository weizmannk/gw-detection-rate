{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "83c09708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functools import partial\n",
    "\n",
    "from astropy import cosmology\n",
    "from astropy.cosmology._utils import vectorize_redshift_method\n",
    "from astropy import units\n",
    "from astropy.units import dimensionless_unscaled\n",
    "import numpy as np\n",
    "from scipy.integrate import quad, fixed_quad\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy import stats\n",
    "\n",
    "from ligo.lw import lsctables\n",
    "from ligo.lw import utils as ligolw_utils\n",
    "from ligo.lw import ligolw\n",
    "import lal.series\n",
    "\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "\n",
    "from ligo.skymap.util import progress_map\n",
    "from ligo.skymap.bayestar.filter import sngl_inspiral_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52c79b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_decisive_snr(snrs, min_triggers):\n",
    "    \"\"\"Return the SNR for the trigger that decides if an event is detectable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    snrs : list\n",
    "        List of SNRs (floats).\n",
    "    min_triggers : int\n",
    "        Minimum number of triggers to form a coincidence.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    decisive_snr : float\n",
    "\n",
    "    \"\"\"\n",
    "    return sorted(snrs)[-min_triggers]\n",
    "\n",
    "\n",
    "def lo_hi_nonzero(x):\n",
    "    nonzero = np.flatnonzero(x)\n",
    "    return nonzero[0], nonzero[-1]\n",
    "\n",
    "\n",
    "class GWCosmo:\n",
    "    \"\"\"Evaluate GW distance figures of merit for a given cosmology.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cosmo : :class:`astropy.cosmology.FLRW`\n",
    "        The cosmological model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cosmology):\n",
    "        self.cosmo = cosmology\n",
    "\n",
    "    def z_at_snr(self, psds, waveform, f_low, snr_threshold, min_triggers,\n",
    "                 mass1, mass2, spin1z, spin2z):\n",
    "        \"\"\"\n",
    "        Get redshift at which a waveform attains a given SNR.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        psds : list\n",
    "            List of :class:`lal.REAL8FrequencySeries` objects.\n",
    "        waveform : str\n",
    "            Waveform approximant name.\n",
    "        f_low : float\n",
    "            Low-frequency cutoff for template.\n",
    "        snr_threshold : float\n",
    "            Minimum single-detector SNR.\n",
    "        min_triggers : int\n",
    "            Minimum number of triggers to form a coincidence.\n",
    "        params : list\n",
    "            List of waveform parameters: mass1, mass2, spin1z, spin2z.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        comoving_distance : float\n",
    "            Comoving distance in Mpc.\n",
    "\n",
    "        \"\"\"\n",
    "        # Construct waveform\n",
    "        series = sngl_inspiral_psd(waveform, f_low=f_low,\n",
    "                                   mass1=mass1, mass2=mass2,\n",
    "                                   spin1z=spin1z, spin2z=spin2z)\n",
    "        i_lo, i_hi = lo_hi_nonzero(series.data.data)\n",
    "        log_f = np.log(series.f0 + series.deltaF * np.arange(i_lo, i_hi + 1))\n",
    "        log_f_lo = log_f[0]\n",
    "        log_f_hi = log_f[-1]\n",
    "        num = interp1d(\n",
    "            log_f, np.log(series.data.data[i_lo:i_hi + 1]),\n",
    "            fill_value=-np.inf, bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        denoms = []\n",
    "        for series in psds:\n",
    "            i_lo, i_hi = lo_hi_nonzero(\n",
    "                np.isfinite(series.data.data) & (series.data.data != 0))\n",
    "            log_f = np.log(\n",
    "                series.f0 + series.deltaF * np.arange(i_lo, i_hi + 1))\n",
    "            denom = interp1d(\n",
    "                log_f, log_f - np.log(series.data.data[i_lo:i_hi + 1]),\n",
    "                fill_value=-np.inf, bounds_error=False, assume_sorted=True)\n",
    "            denoms.append(denom)\n",
    "\n",
    "        def snr_at_z(z):\n",
    "            logzp1 = np.log(z + 1)\n",
    "            integrand = lambda log_f: [\n",
    "                np.exp(num(log_f + logzp1) + denom(log_f)) for denom in denoms]\n",
    "            integrals, _ = fixed_quad(\n",
    "                integrand, log_f_lo, log_f_hi - logzp1, n=1024)\n",
    "            snr = get_decisive_snr(np.sqrt(4 * integrals), min_triggers)\n",
    "            with np.errstate(divide='ignore'):\n",
    "                snr /= self.cosmo.angular_diameter_distance(z).to_value(\n",
    "                    units.Mpc)\n",
    "            return snr\n",
    "\n",
    "        def root_func(z):\n",
    "            return snr_at_z(z) - snr_threshold\n",
    "\n",
    "        return root_scalar(root_func, bracket=(0, 1e3)).root\n",
    "\n",
    "    def get_max_z(self, psds, waveform, f_low, snr_threshold, min_triggers,\n",
    "                  mass1, mass2, spin1z, spin2z, jobs=1):\n",
    "        # Calculate the maximum distance on the grid.\n",
    "        params = [mass1, mass2, spin1z, spin2z]\n",
    "        shape = np.broadcast_shapes(*(param.shape for param in params))\n",
    "        result = list(progress_map(\n",
    "            partial(self.z_at_snr, psds, waveform, f_low,\n",
    "                    snr_threshold, min_triggers),\n",
    "            *(param.ravel() for param in params),\n",
    "            jobs=jobs))\n",
    "        result = np.reshape(result, shape)\n",
    "\n",
    "        assert np.all(result >= 0), 'some redshifts are negative'\n",
    "        assert np.all(np.isfinite(result)), 'some redshifts are not finite'\n",
    "        return result\n",
    "\n",
    "    @vectorize_redshift_method\n",
    "    def _sensitive_volume_integral(self, z):\n",
    "        dh3_sr = self.cosmo.hubble_distance**3 / units.sr\n",
    "\n",
    "        def integrand(z):\n",
    "            result = self.cosmo.differential_comoving_volume(z)\n",
    "            result /= (1 + z) * dh3_sr\n",
    "            return result.to_value(dimensionless_unscaled)\n",
    "\n",
    "        result, _ = quad(integrand, 0, z)\n",
    "        return result\n",
    "\n",
    "    def sensitive_volume(self, z):\n",
    "        \"\"\"Sensitive volume :math:`V(z)` out to redshift :math:`z`.\n",
    "\n",
    "        Given a population of events that occur at a constant rate density\n",
    "        :math:`R` per unit comoving volume per unit proper time, the number of\n",
    "        observed events out to a redshift :math:`N(z)` over an observation time\n",
    "        :math:`T` is :math:`N(z) = R T V(z)`.\n",
    "        \"\"\"\n",
    "        dh3 = self.cosmo.hubble_distance**3\n",
    "        return 4 * np.pi * dh3 * self._sensitive_volume_integral(z)\n",
    "\n",
    "    def sensitive_distance(self, z):\n",
    "        r\"\"\"Sensitive distance as a function of redshift :math:`z`.\n",
    "\n",
    "        The sensitive distance is the distance :math:`d_s(z)` defined such that\n",
    "        :math:`V(z) = 4/3\\pi {d_s(z)}^3`, where :math:`V(z)` is the sensitive\n",
    "        volume.\n",
    "        \"\"\"\n",
    "        dh = self.cosmo.hubble_distance\n",
    "        return dh * np.cbrt(3 * self._sensitive_volume_integral(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473d301",
   "metadata": {},
   "source": [
    "    # ----------------- Execution & Example -----------------\n",
    "\n",
    "##### 1. We load the noise Power Spectral Densities (PSDs) from the XML file.\n",
    "#####    These PSDs are used to compute signal-to-noise ratios (SNRs) across detectors.\n",
    "\n",
    "##### Initialize a new LIGO Light-Weight XML document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6ded26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldoc = ligolw.Document()\n",
    "xmlroot = xmldoc.appendChild(ligolw.LIGO_LW())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27616a61",
   "metadata": {},
   "source": [
    "#### Initialize a new LIGO Light-Weight XML document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3424f6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Swig Object of type 'tagREAL8FrequencySeries *' at 0x19b6e0c70>,\n",
       " <Swig Object of type 'tagREAL8FrequencySeries *' at 0x19b88c130>,\n",
       " <Swig Object of type 'tagREAL8FrequencySeries *' at 0x19b7045f0>,\n",
       " <Swig Object of type 'tagREAL8FrequencySeries *' at 0x19b706530>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_psd = \"psds.xml\"\n",
    "with open(reference_psd, \"rb\") as f:\n",
    "    xmldoc = ligolw_utils.load_fileobj(f, contenthandler=lal.series.PSDContentHandler)\n",
    "    psds = list(lal.series.read_psd_xmldoc(xmldoc).values())\n",
    "\n",
    "psds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a3457",
   "metadata": {},
   "source": [
    "#### 2. We define the waveform model, the low-frequency cutoff, and the detection thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d6f358e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "waveform = \"IMRPhenomD\"  # Chosen waveform approximant\n",
    "f_low = 25.               # Low-frequency cutoff in Hz\n",
    "snr_threshold = 1         # SNR threshold for detection\n",
    "min_triggers = 1          # Minimum number of triggers (coincident detectors)\n",
    "jobs = 1                  # Number of parallel jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289badd",
   "metadata": {},
   "source": [
    "\n",
    "##### 3. We initialize the GWCosmo object with a cosmological model (Planck15 here).\n",
    "#####    This allows us to compute distances and volumes in a cosmological framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35c8d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gwcosmo = GWCosmo(getattr(cosmology, \"Planck15\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f50acf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### 4. We load a subset (first 5) of the binary neutron star / black hole samples \n",
    "#####    from an HDF5 file (`farah.h5`). Each sample includes mass1, mass2, spin1z, spin2z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b42677f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=5</i>\n",
       "<table id=\"table6899570768\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>mass1</th><th>mass2</th><th>spin1z</th><th>spin2z</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>1.6334784673051967</td><td>1.3810887548655666</td><td>0.0005726141112029242</td><td>-0.012026548338777296</td></tr>\n",
       "<tr><td>2.4116235511053596</td><td>2.038928316809099</td><td>0.09564577831587825</td><td>0.12876640961108698</td></tr>\n",
       "<tr><td>2.3446204414808824</td><td>2.1620985552733023</td><td>-0.0424013188343698</td><td>0.20299660662345526</td></tr>\n",
       "<tr><td>1.5224413917381097</td><td>1.4464455008707857</td><td>0.056652858388635034</td><td>0.1648556391943954</td></tr>\n",
       "<tr><td>2.071907865468317</td><td>1.757569633659934</td><td>0.0721102841575518</td><td>-0.06863285853206544</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "      mass1              mass2        ...         spin2z       \n",
       "     float64            float64       ...        float64       \n",
       "------------------ ------------------ ... ---------------------\n",
       "1.6334784673051967 1.3810887548655666 ... -0.012026548338777296\n",
       "2.4116235511053596  2.038928316809099 ...   0.12876640961108698\n",
       "2.3446204414808824 2.1620985552733023 ...   0.20299660662345526\n",
       "1.5224413917381097 1.4464455008707857 ...    0.1648556391943954\n",
       " 2.071907865468317  1.757569633659934 ...  -0.06863285853206544"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "distribution_samples = \"farah.h5\"\n",
    "samples = Table.read(distribution_samples)[0:5]\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacdc51",
   "metadata": {},
   "source": [
    "#### 5. For each sample, we compute the maximum redshift `max_z` where the SNR\n",
    "####    exceeds the chosen threshold, using all available PSDs. This uses the full\n",
    "####    PSD frequency content for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "80491bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7187c18a32084dbda953ede7ddf29486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.90879562, 3.01082865, 3.05186255, 1.90409028, 2.49130032])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_z = gwcosmo.get_max_z(\n",
    "    psds, waveform, f_low,\n",
    "    snr_threshold, min_triggers,\n",
    "    samples['mass1'], samples['mass2'],\n",
    "    samples['spin1z'], samples['spin2z'], jobs=jobs)\n",
    "\n",
    "max_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fcd5a6",
   "metadata": {},
   "source": [
    "\n",
    "#### 6. We then convert `max_z` to a comoving sensitive distance (in Mpc),\n",
    "####    using the cosmological model. Since `max_z` is a vector, this step must be\n",
    "####    applied element-by-element to avoid errors with array-valued integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f442c909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3998.333539  , 4707.80752121, 4726.72584292, 3994.16514986,\n",
       "       4429.10918943])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance = gwcosmo.sensitive_distance(max_z).to_value(units.Mpc)\n",
    "max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32038c0d",
   "metadata": {},
   "source": [
    "#### 7. With the resulting distances, we compute volumes proportional to each sample's \n",
    "####    detection range: V ~ (4/3)π * distance**3. These volumes define selection probabilities.\n",
    "#### Calculate V * T for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed4c45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform weight per sample, each distance contributes equally at first. \n",
    "probs = 1 / len(max_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c8988",
   "metadata": {},
   "source": [
    "\n",
    "### We changes equal probabilities into ones that depend on how much space (volume) we can see at each distance.\n",
    "### Since sources are spread evenly in space, the farther we can see, the more space we cover,\n",
    "###  so the chance of finding a source there is higher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03cc51b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.35495302e+10 8.74127333e+10 8.84707777e+10 5.33822235e+10\n",
      " 7.27893374e+10]\n"
     ]
    }
   ],
   "source": [
    "probs *= 4/3*np.pi*max_distance**3\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65c8a2",
   "metadata": {},
   "source": [
    "#### Each probability is divided by the total sum to make the whole add up to 1.\n",
    "#### This gives a proper probability distribution.\n",
    "\n",
    "#### We normalize the volumes to use them as probabilities to draw synthetic events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d4dea663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of prob : 355604601947.13995\n",
      "\n",
      " probs : \n",
      "\n",
      " [0.15058728 0.2458144  0.24878974 0.1501168  0.20469178]\n",
      "\n",
      " sum of  correct probs : 1.0\n"
     ]
    }
   ],
   "source": [
    "volume = probs.sum()\n",
    "print(\"sum of prob :\", volume)\n",
    "probs /= volume\n",
    "print(\"\\n probs : \\n\\n\", probs)\n",
    "print(\"\\n sum of  correct probs :\", probs.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5443ef8",
   "metadata": {},
   "source": [
    "\n",
    "#### Draw weighted samples for the simulated events.\n",
    "### or Create the weighted distribution object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0dff8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = len(samples)\n",
    "dist = stats.rv_discrete(values=(np.arange(len(probs)), probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4254b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = max(nsamples * len(probs) // 1_000_000_000, 1)\n",
    "batch_sizes = [len(subarray) for subarray in np.array_split(np.empty(nsamples), n_batches)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe1a28a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 4, 2])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.concatenate([dist.rvs(size=batch_size) for batch_size in batch_sizes])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b06d2fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mass1': <Column name='mass1' dtype='float64' length=5>\n",
       " 2.4116235511053596\n",
       " 1.6334784673051967\n",
       " 1.6334784673051967\n",
       "  2.071907865468317\n",
       " 2.3446204414808824,\n",
       " 'mass2': <Column name='mass2' dtype='float64' length=5>\n",
       "  2.038928316809099\n",
       " 1.3810887548655666\n",
       " 1.3810887548655666\n",
       "  1.757569633659934\n",
       " 2.1620985552733023,\n",
       " 'spin1z': <Column name='spin1z' dtype='float64' length=5>\n",
       "   0.09564577831587825\n",
       " 0.0005726141112029242\n",
       " 0.0005726141112029242\n",
       "    0.0721102841575518\n",
       "   -0.0424013188343698,\n",
       " 'spin2z': <Column name='spin2z' dtype='float64' length=5>\n",
       "   0.12876640961108698\n",
       " -0.012026548338777296\n",
       " -0.012026548338777296\n",
       "  -0.06863285853206544\n",
       "   0.20299660662345526}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = {key: samples[key][indices] for key in ['mass1', 'mass2', 'spin1z', 'spin2z']}\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "169a8413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$1.406056 \\times 10^{-11} \\; \\mathrm{\\frac{1}{yr\\,Mpc^{3}}}$"
      ],
      "text/plain": [
       "<Quantity 1.40605604e-11 1 / (yr Mpc3)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volumetric_rate = (nsamples / volume * units.year**-1 * units.Mpc**-3)\n",
    "volumetric_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "48116f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 4, 2])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4e5a9",
   "metadata": {},
   "source": [
    "#### So now dist.rvs() can randomly draw indices, favoring higher-probability ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09846c",
   "metadata": {},
   "source": [
    "### Processing with All Simulations\n",
    "\n",
    "After processing all the simulations, we will consider the new observing scenarios based on the GWTC-3 catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a0ab6167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4217.64552343, 3122.04194864, 3196.4871486 , 4329.60527525,\n",
       "       2012.33325463])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw random extrinsic parameters\n",
    "distance = stats.powerlaw(a=3, scale=max_distance[indices]).rvs(size=nsamples)\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c71093",
   "metadata": {},
   "source": [
    "### We need to standardize our rate base on the initial distribution rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ee06b04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902637840\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>100.0</td><td>240.0</td><td>510.0</td></tr>\n",
       "<tr><td>NSBH</td><td>100.0</td><td>240.0</td><td>510.0</td></tr>\n",
       "<tr><td>BBH</td><td>100.0</td><td>240.0</td><td>510.0</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population  lower    mid    upper \n",
       "   str4    float64 float64 float64\n",
       "---------- ------- ------- -------\n",
       "       BNS   100.0   240.0   510.0\n",
       "      NSBH   100.0   240.0   510.0\n",
       "       BBH   100.0   240.0   510.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower 5% and upper 95% quantiles of log-normal distribution for different CBC populations\n",
    "run_names = [\"O4\", \"O5\"]\n",
    "rates_table = Table(\n",
    "    [\n",
    "        # Quantiles from O3 R&P paper Table II, row 1, last column\n",
    "        {\"population\": \"BNS\", \"lower\": 100.0, \"mid\": 240.0, \"upper\": 510.0},\n",
    "        {\"population\": \"NSBH\", \"lower\": 100.0, \"mid\": 240.0, \"upper\": 510.0},\n",
    "        {\"population\": \"BBH\", \"lower\": 100.0, \"mid\": 240.0, \"upper\": 510.0},\n",
    "    ]\n",
    ")\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320027b",
   "metadata": {},
   "source": [
    "#### Splitting Compact Binary Populations\n",
    "\n",
    "To classify events as BNS (Binary Neutron Star), NSBH (Neutron Star–Black Hole), or BBH (Binary Black Hole),  \n",
    "we use an upper/lower mass limit of 3 solar masses to distinguish neutron stars (NS) from black holes (BH).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3cc08b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_max_mass = 3.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8af39f",
   "metadata": {},
   "source": [
    "#### Injection Summary\n",
    "\n",
    "We injected a total of **1 million** compact binary coalescences (CBCs), consisting of:\n",
    "- **892,762** binary neutron stars (BNS)\n",
    "- **35,962** neutron star–black hole binaries (NSBH)\n",
    "- **71,276** binary black holes (BBH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "52353238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902637840\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th><th>mass_fraction</th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>100.0</td><td>240.0</td><td>510.0</td><td>0.892762</td></tr>\n",
       "<tr><td>NSBH</td><td>100.0</td><td>240.0</td><td>510.0</td><td>0.035962</td></tr>\n",
       "<tr><td>BBH</td><td>100.0</td><td>240.0</td><td>510.0</td><td>0.071276</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population  lower    mid    upper  mass_fraction\n",
       "   str4    float64 float64 float64    float64   \n",
       "---------- ------- ------- ------- -------------\n",
       "       BNS   100.0   240.0   510.0      0.892762\n",
       "      NSBH   100.0   240.0   510.0      0.035962\n",
       "       BBH   100.0   240.0   510.0      0.071276"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mass fraction for each CBC population (BNS, NSBH, BBH) \n",
    "# by dividing the population count by the total number of CBCs (1 million)\n",
    "rates_table[\"mass_fraction\"] = np.array([892762, 35962, 71276]) / 1e6  # Total CBCs = 1 million\n",
    "\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2207cad",
   "metadata": {},
   "source": [
    "##### === Simulated BNS Merger Rates ===\n",
    "In observing scenarios data there is a file sqlite  file \"sqlite3 events.sqlite\" where we can read the \n",
    "the simulation Merger rate, for that use this command line in terminal or import sqlite with python \n",
    "\n",
    " Use this command to retrieve comments:\n",
    "\n",
    " 1- $ sqlite3 events.sqlite\n",
    "\n",
    " 2- $ select comment from process;\n",
    "\n",
    "For example: The simulated CBC merger rate in yr^-1 Gpc^-3 for O5 and O6-HLVK configuration with (SNR = 10)\n",
    "\n",
    "From kiendrebeogo et al. 2023 the simulated rate is given by the by (yr^-1 Mpc^-3)\n",
    "\n",
    "so this need to be convert in yr^-1 Gpc^-3, before add use it here.\n",
    "\n",
    "simulation rate  sim_rate =2.712359951521142e3 (u.Gpc**-3 * u.yr**-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70264341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Column name='sim_rate_O4' dtype='float64' unit='1 / (yr Gpc3)' length=3>\n",
       " 6546.207595945649\n",
       " 6546.207595945649\n",
       " 6546.207595945649,\n",
       " <Column name='sim_rate_O5' dtype='float64' unit='1 / (yr Gpc3)' length=3>\n",
       " 2712.3599515211436\n",
       " 2712.3599515211436\n",
       " 2712.3599515211436)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here BNS, BBH and NSBH have the same simulation rates as they have been simulated together.\n",
    "rates_table[\"sim_rate_O4\"] = [6.5462076e-06, 6.5462076e-06, 6.5462076e-06] * (1 / (u.Mpc**3 * u.yr))\n",
    "rates_table[\"sim_rate_O5\"] = [2.712359951521143e-06, 2.712359951521143e-06, 2.712359951521143e-06] * (1 / (u.Mpc**3 * u.yr))\n",
    "\n",
    "\n",
    "# Conversion in Gpc^-3/ yr\n",
    "rates_table[\"sim_rate_O4\"] = rates_table[\"sim_rate_O4\"].to(u.Gpc**-3 * u.yr**-1)\n",
    "rates_table[\"sim_rate_O5\"] = rates_table[\"sim_rate_O5\"].to(u.Gpc**-3 * u.yr**-1)\n",
    "\n",
    "rates_table[\"sim_rate_O4\"], rates_table[\"sim_rate_O5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37996f0c",
   "metadata": {},
   "source": [
    "# Add the expected number of detections for O4 and O5\n",
    "\n",
    "Here the SNR theshold to confirm a detection is 8.\n",
    "\n",
    "So all those event have a signal noise ratio > 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "38806733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902637840\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th><th>mass_fraction</th><th>sim_rate_O4</th><th>sim_rate_O5</th><th>detection_number_O4</th><th>detection_number_O5</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th></th><th></th><th></th><th>1 / (yr Gpc3)</th><th>1 / (yr Gpc3)</th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>int64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>100.0</td><td>240.0</td><td>510.0</td><td>0.892762</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>1004</td><td>2003</td></tr>\n",
       "<tr><td>NSBH</td><td>100.0</td><td>240.0</td><td>510.0</td><td>0.035962</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>184</td><td>356</td></tr>\n",
       "<tr><td>BBH</td><td>100.0</td><td>240.0</td><td>510.0</td><td>0.071276</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>7070</td><td>9809</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population  lower    mid   ... detection_number_O4 detection_number_O5\n",
       "                           ...                                        \n",
       "   str4    float64 float64 ...        int64               int64       \n",
       "---------- ------- ------- ... ------------------- -------------------\n",
       "       BNS   100.0   240.0 ...                1004                2003\n",
       "      NSBH   100.0   240.0 ...                 184                 356\n",
       "       BBH   100.0   240.0 ...                7070                9809"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rates_table[\"detection_number_O4\"] = np.array([1004, 184, 7070])\n",
    "rates_table[\"detection_number_O5\"] = np.array([2003, 356, 9809])\n",
    "\n",
    "rates_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444aec20",
   "metadata": {},
   "source": [
    "# Scaling Quantiles by Mass Fraction\n",
    "\n",
    "For each CBC population, we scale the lower, median, and upper event rate quantiles by `mass_fraction` column. \n",
    "\n",
    "This can be used, for example, to focus on a sub-population or a fraction of events relevant to a specific analysis.\n",
    "\n",
    "> **Note:** Make sure that the `mass_fraction` column exists and has appropriate values (between 0 and 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0f806a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902637840\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th><th>mass_fraction</th><th>sim_rate_O4</th><th>sim_rate_O5</th><th>detection_number_O4</th><th>detection_number_O5</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th></th><th></th><th></th><th>1 / (yr Gpc3)</th><th>1 / (yr Gpc3)</th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>int64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>89.27619999999999</td><td>214.26288</td><td>455.30861999999996</td><td>0.892762</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>1004</td><td>2003</td></tr>\n",
       "<tr><td>NSBH</td><td>3.5962</td><td>8.63088</td><td>18.34062</td><td>0.035962</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>184</td><td>356</td></tr>\n",
       "<tr><td>BBH</td><td>7.127600000000001</td><td>17.10624</td><td>36.35076</td><td>0.071276</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>7070</td><td>9809</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population       lower       ... detection_number_O4 detection_number_O5\n",
       "                             ...                                        \n",
       "   str4         float64      ...        int64               int64       \n",
       "---------- ----------------- ... ------------------- -------------------\n",
       "       BNS 89.27619999999999 ...                1004                2003\n",
       "      NSBH            3.5962 ...                 184                 356\n",
       "       BBH 7.127600000000001 ...                7070                9809"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in [\"lower\", \"mid\", \"upper\"]:\n",
    "    rates_table[key] *= rates_table['mass_fraction']\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d647abd",
   "metadata": {},
   "source": [
    "## Compute Log-normal Parameters from Quantiles\n",
    "\n",
    "For each population, we calculate the mean (`mu`) and standard deviation (`sigma`) of the underlying log-normal distribution.\n",
    "- `mu` is the mean of the logarithm of the median event rate.\n",
    "- `sigma` is set so that the interval between the lower and upper quantile matches the standard width of a 90% normal interval (from 5% to 95% quantile).\n",
    "\n",
    "This is useful for statistical modeling or simulations where log-normal priors are assumed for event rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ab1be018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902637840\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th><th>mass_fraction</th><th>sim_rate_O4</th><th>sim_rate_O5</th><th>detection_number_O4</th><th>detection_number_O5</th><th>mu</th><th>sigma</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th></th><th></th><th></th><th>1 / (yr Gpc3)</th><th>1 / (yr Gpc3)</th><th></th><th></th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>int64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>89.27619999999999</td><td>214.26288</td><td>455.30861999999996</td><td>0.892762</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>1004</td><td>2003</td><td>5.367203672357068</td><td>0.49525395847832065</td></tr>\n",
       "<tr><td>NSBH</td><td>3.5962</td><td>8.63088</td><td>18.34062</td><td>0.035962</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>184</td><td>356</td><td>2.1553464697693</td><td>0.49525395847832093</td></tr>\n",
       "<tr><td>BBH</td><td>7.127600000000001</td><td>17.10624</td><td>36.35076</td><td>0.071276</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>7070</td><td>9809</td><td>2.8394433092250226</td><td>0.4952539584783208</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population       lower       ...         mu                sigma       \n",
       "                             ...                                       \n",
       "   str4         float64      ...      float64             float64      \n",
       "---------- ----------------- ... ------------------ -------------------\n",
       "       BNS 89.27619999999999 ...  5.367203672357068 0.49525395847832065\n",
       "      NSBH            3.5962 ...    2.1553464697693 0.49525395847832093\n",
       "       BBH 7.127600000000001 ... 2.8394433092250226  0.4952539584783208"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_90pct_interval, = np.diff(stats.norm.interval(0.9))\n",
    "rates_table['mu'] = np.log(rates_table['mid'])\n",
    "rates_table['sigma'] = (np.log(rates_table['upper']) - np.log(rates_table['lower'])) / standard_90pct_interval\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "da0c49ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.36720367, 2.15534647, 2.83944331]),\n",
       " array([0.49525396, 0.49525396, 0.49525396]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the log-normal parameters for each population as numpy arrays\n",
    "fiducial_log_rates = np.asarray(rates_table['mu'])\n",
    "fiducial_log_rate_errs = np.asarray(rates_table['sigma'])\n",
    "\n",
    "fiducial_log_rates , fiducial_log_rate_errs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600254",
   "metadata": {},
   "source": [
    "### Add Log-normal Parameters to the Table\n",
    "\n",
    "For convenience, we add the log-normal mean (`fiducial_log_rate`) and standard deviation (`fiducial_log_rate_err`) as new columns in the `rates_table`.  \n",
    "This keeps all relevant parameters together and makes the table easy to use for further analysis or plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3733dbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902637840\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th><th>mass_fraction</th><th>sim_rate_O4</th><th>sim_rate_O5</th><th>detection_number_O4</th><th>detection_number_O5</th><th>mu</th><th>sigma</th><th>fiducial_log_rate</th><th>fiducial_log_rate_err</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th></th><th></th><th></th><th>1 / (yr Gpc3)</th><th>1 / (yr Gpc3)</th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>89.27619999999999</td><td>214.26288</td><td>455.30861999999996</td><td>0.892762</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>1004</td><td>2003</td><td>5.367203672357068</td><td>0.49525395847832065</td><td>5.367203672357068</td><td>0.49525395847832065</td></tr>\n",
       "<tr><td>NSBH</td><td>3.5962</td><td>8.63088</td><td>18.34062</td><td>0.035962</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>184</td><td>356</td><td>2.1553464697693</td><td>0.49525395847832093</td><td>2.1553464697693</td><td>0.49525395847832093</td></tr>\n",
       "<tr><td>BBH</td><td>7.127600000000001</td><td>17.10624</td><td>36.35076</td><td>0.071276</td><td>6546.207595945649</td><td>2712.3599515211436</td><td>7070</td><td>9809</td><td>2.8394433092250226</td><td>0.4952539584783208</td><td>2.8394433092250226</td><td>0.4952539584783208</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population       lower       ... fiducial_log_rate  fiducial_log_rate_err\n",
       "                             ...                                         \n",
       "   str4         float64      ...      float64              float64       \n",
       "---------- ----------------- ... ------------------ ---------------------\n",
       "       BNS 89.27619999999999 ...  5.367203672357068   0.49525395847832065\n",
       "      NSBH            3.5962 ...    2.1553464697693   0.49525395847832093\n",
       "       BBH 7.127600000000001 ... 2.8394433092250226    0.4952539584783208"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_table['fiducial_log_rate'] = fiducial_log_rates\n",
    "rates_table['fiducial_log_rate_err'] =  fiducial_log_rate_errs\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a97eea",
   "metadata": {},
   "source": [
    "#### Functions for propagating errors in rates\n",
    "\n",
    "Reproduced from https://github.com/lpsinger/observing-scenarios-simulations/blob/main/plots-and-tables.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "36c0c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import integrate, optimize, special, stats\n",
    "\n",
    "\n",
    "def betabinom_k_n(k, n):\n",
    "    return stats.betabinom(n, k + 1, n - k + 1)\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def poisson_lognormal_rate_cdf(k, mu, sigma):\n",
    "    lognorm_pdf = stats.lognorm(s=sigma, scale=np.exp(mu)).pdf\n",
    "\n",
    "    def func(lam):\n",
    "        prior = lognorm_pdf(lam)\n",
    "        # poisson_pdf = np.exp(special.xlogy(k, lam) - special.gammaln(k + 1) - lam)\n",
    "        poisson_cdf = special.gammaincc(k + 1, lam)\n",
    "        return poisson_cdf * prior\n",
    "\n",
    "    # Marginalize over lambda.\n",
    "    #\n",
    "    # Note that we use scipy.integrate.odeint instead\n",
    "    # of scipy.integrate.quad because it is important for the stability of\n",
    "    # root_scalar below that we calculate the pdf and the cdf at the same time,\n",
    "    # using the same exact quadrature rule.\n",
    "    cdf, _ = integrate.quad(func, 0, np.inf, epsabs=0)\n",
    "    return cdf\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def poisson_lognormal_rate_quantiles(p, mu, sigma):\n",
    "    \"\"\"Find the quantiles of a Poisson distribution with\n",
    "    a log-normal prior on its rate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : float\n",
    "        The quantiles at which to find the number of counts.\n",
    "    mu : float\n",
    "        The mean of the log of the rate.\n",
    "    sigma : float\n",
    "        The standard deviation of the log of the rate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    k : float\n",
    "        The number of events.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This algorithm treats the Poisson count k as a continuous\n",
    "    real variable so that it can use the scipy.optimize.root_scalar\n",
    "    root finding/polishing algorithms.\n",
    "    \"\"\"\n",
    "\n",
    "    def func(k):\n",
    "        return poisson_lognormal_rate_cdf(k, mu, sigma) - p\n",
    "\n",
    "    if func(0) >= 0:\n",
    "        return 0\n",
    "\n",
    "    result = optimize.root_scalar(func, bracket=[0, 1e6])\n",
    "    return result.root\n",
    "\n",
    "\n",
    "def format_with_errorbars(mid, lo, hi):\n",
    "    plus = hi - mid\n",
    "    minus = mid - lo\n",
    "    smallest = min(max(0, plus), max(0, minus))\n",
    "\n",
    "    if smallest == 0:\n",
    "        return str(mid), \"0\", \"0\"\n",
    "    decimals = 1 - int(np.floor(np.log10(smallest)))\n",
    "\n",
    "    if all(np.issubdtype(type(_), np.integer) for _ in (mid, lo, hi)):\n",
    "        decimals = min(decimals, 0)\n",
    "\n",
    "    plus, minus, mid = np.round([plus, minus, mid], decimals)\n",
    "    if decimals > 0:\n",
    "        fstring = \"%%.0%df\" % decimals\n",
    "    else:\n",
    "        fstring = \"%d\"\n",
    "    return [fstring % _ for _ in [mid, minus, plus]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ce050",
   "metadata": {},
   "source": [
    "### Set Probability Quantiles and Run Duration\n",
    "\n",
    "- `prob_quantiles` defines the lower (5%), median (50%), and upper (95%) quantiles used for statistical calculations.\n",
    "- `run_duration` is the duration of the observing run in years.  \n",
    "You can adjust this value if you need rates for a different observation period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bad0e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_quantiles = np.asarray([0.05, 0.5, 0.95])\n",
    "run_duration = 1.0  # years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc551a",
   "metadata": {},
   "source": [
    "### Detection Number Quantiles Table\n",
    "\n",
    "This block computes the 5%, 50%, and 95% quantiles for the expected number of detections for each CBC population and run, based on log-normal statistics.\n",
    "\n",
    "**Table columns:**\n",
    "- `run`: Observing run (e.g., O4, O5)\n",
    "- `population`: Source type (BNS, NSBH, BBH)\n",
    "- `lo`, `mid`, `hi`: Lower, median, and upper quantiles for the expected number of detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97dfcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.220903011741974 36.29137413459341 84.26422042896877\n",
      "1.16782118991067 6.17832366750649 16.28001123047519\n",
      "112.62898612831737 258.700770567042 586.5212336090926\n",
      "76.33752370913136 176.729131286245 401.40447775663256\n",
      "11.882852213825503 30.979862711663 72.27134602782732\n",
      "382.1724593427413 867.4370725981714 1961.239365996027\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "for run_name in run_names:\n",
    "    results[run_name] = {}\n",
    "\n",
    "    for pop in ['BNS', 'NSBH', 'BBH']:\n",
    "\n",
    "        rates_row = rates_table[rates_table['population'] == pop]\n",
    "        rate = rates_row[f'sim_rate_{run_name}'] * rates_row['mass_fraction']\n",
    "\n",
    "        mu =  rates_row['fiducial_log_rate']  + np.log(run_duration)  + np.log(rates_row[f'detection_number_{run_name}'] / rate)\n",
    "        sigma  = rates_row['fiducial_log_rate_err']\n",
    "\n",
    "        lo, mid, hi = poisson_lognormal_rate_quantiles(prob_quantiles, mu, sigma)\n",
    "        print(  lo, mid, hi)\n",
    "        lo = int(np.floor(lo))\n",
    "        mid = int(np.round(mid))\n",
    "        hi = int(np.ceil(hi))\n",
    "\n",
    "        mid, lo, hi = format_with_errorbars(mid, lo, hi)\n",
    "        \n",
    "        results[run_name].setdefault('low', {})[pop] = lo\n",
    "        results[run_name] .setdefault('mid', {})[pop] = mid\n",
    "        results[run_name] .setdefault('high', {})[pop] = hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4141b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for run_name, stats in results.items():\n",
    "    for pop in stats['mid']:\n",
    "        rows.append({\n",
    "            \"run\": run_name,\n",
    "            \"population\": pop,\n",
    "            \"low\": f\"-{stats['low'][pop]}\",\n",
    "            \"mid\": stats['mid'][pop],\n",
    "            \"high\": f\"+{stats['high'][pop]}\",\n",
    "        })\n",
    "\n",
    "results_table = Table(rows=rows, names=(\"run\", \"population\", \"low\", \"mid\", \"high\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "19755481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=6</i>\n",
       "<table id=\"table6902539920\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>run</th><th>population</th><th>low</th><th>mid</th><th>high</th></tr></thead>\n",
       "<thead><tr><th>str2</th><th>str4</th><th>str4</th><th>str3</th><th>str5</th></tr></thead>\n",
       "<tr><td>O4</td><td>BNS</td><td>-22</td><td>36</td><td>+49</td></tr>\n",
       "<tr><td>O4</td><td>NSBH</td><td>-5</td><td>6</td><td>+11</td></tr>\n",
       "<tr><td>O4</td><td>BBH</td><td>-150</td><td>260</td><td>+330</td></tr>\n",
       "<tr><td>O5</td><td>BNS</td><td>-100</td><td>180</td><td>+220</td></tr>\n",
       "<tr><td>O5</td><td>NSBH</td><td>-20</td><td>31</td><td>+42</td></tr>\n",
       "<tr><td>O5</td><td>BBH</td><td>-480</td><td>870</td><td>+1100</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=6>\n",
       "run  population low  mid   high\n",
       "str2    str4    str4 str3  str5\n",
       "---- ---------- ---- ---- -----\n",
       "  O4        BNS  -22   36   +49\n",
       "  O4       NSBH   -5    6   +11\n",
       "  O4        BBH -150  260  +330\n",
       "  O5        BNS -100  180  +220\n",
       "  O5       NSBH  -20   31   +42\n",
       "  O5        BBH -480  870 +1100"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ba1677d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Observing Run O4 : Annual number of detections\n",
      "===============================================\n",
      "run population low  mid high\n",
      "--- ---------- ---- --- ----\n",
      " O4        BNS  -22  36  +49\n",
      " O4       NSBH   -5   6  +11\n",
      " O4        BBH -150 260 +330\n",
      "===============================================\n",
      "\n",
      " Observing Run O5 : Annual number of detections\n",
      "===============================================\n",
      "run population low  mid  high\n",
      "--- ---------- ---- --- -----\n",
      " O5        BNS -100 180  +220\n",
      " O5       NSBH  -20  31   +42\n",
      " O5        BBH -480 870 +1100\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "# display by run\n",
    "for run_name in sorted(set(results_table['run'])):\n",
    "    print(f\"\\n Observing Run {run_name} : Annual number of detections\")\n",
    "    print(\"=\" * 47)\n",
    "    print(results_table[results_table['run'] == run_name])\n",
    "    print(\"=\" * 47)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753f9f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc113583",
   "metadata": {},
   "source": [
    "# For Petrov et al. 2O22 , design as LRR distribustion, \n",
    "\n",
    "the BNS , NSBH and BBH as consider as a population not a sub-pospulation from CBC ,\n",
    "\n",
    "In fact we simulate each population independently to the other ones, so 1 million each.\n",
    "\n",
    "This means there is no longer a mass fraction or simply means the mass fraction is 1 because as we simulate each population at one time.\n",
    "This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a777824f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902541136\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>80.0</td><td>320.0</td><td>810.0</td></tr>\n",
       "<tr><td>NSBH</td><td>61.0</td><td>130.0</td><td>242.0</td></tr>\n",
       "<tr><td>BBH</td><td>15.3</td><td>23.9</td><td>38.2</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population  lower    mid    upper \n",
       "   str4    float64 float64 float64\n",
       "---------- ------- ------- -------\n",
       "       BNS    80.0   320.0   810.0\n",
       "      NSBH    61.0   130.0   242.0\n",
       "       BBH    15.3    23.9    38.2"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower 5% and upper 95% quantiles of log-normal distribution for different CBC populations\n",
    "run_names = [\"O4\", \"O5\"]\n",
    "rates_table = Table(\n",
    "    [\n",
    "    # BNS rate from GWTC-2\n",
    "    # https://doi.org/10.3847/2041-8213/abe949\n",
    "    {'population': 'BNS', 'lower': 80.00, 'mid': 320.0, 'upper': 810.0},\n",
    "    # NSBH rate from GW200105 and GW200115 paper\n",
    "    # https://doi.org/10.3847/2041-8213/ac082e\n",
    "    {'population': 'NSBH', 'lower': 61.0, 'mid': 130.0, 'upper': 242.0},\n",
    "    # BBH rate from GWTC-2\n",
    "    # https://doi.org/10.3847/2041-8213/abe949\n",
    "    {'population': 'BBH', 'lower': 15.3, 'mid': 23.9, 'upper': 38.2}\n",
    "    ]\n",
    ")\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6f41ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902541136\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th><th>detection_number_O4</th><th>detection_number_O5</th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>int64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>80.0</td><td>320.0</td><td>810.0</td><td>1482</td><td>2307</td></tr>\n",
       "<tr><td>NSBH</td><td>61.0</td><td>130.0</td><td>242.0</td><td>2492</td><td>5441</td></tr>\n",
       "<tr><td>BBH</td><td>15.3</td><td>23.9</td><td>38.2</td><td>6040</td><td>21559</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population  lower    mid    upper  detection_number_O4 detection_number_O5\n",
       "   str4    float64 float64 float64        int64               int64       \n",
       "---------- ------- ------- ------- ------------------- -------------------\n",
       "       BNS    80.0   320.0   810.0                1482                2307\n",
       "      NSBH    61.0   130.0   242.0                2492                5441\n",
       "       BBH    15.3    23.9    38.2                6040               21559"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_table[\"detection_number_O4\"] = np.array([1482, 2492, 6040])\n",
    "rates_table[\"detection_number_O5\"] = np.array([2307, 5441, 21559])\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "21609940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Column name='sim_rate_O4' dtype='float64' unit='1 / (yr Gpc3)' length=3>\n",
       " 13598.513465134649\n",
       "  4462.124683568845\n",
       " 1355.9875568260693,\n",
       " <Column name='sim_rate_O5' dtype='float64' unit='1 / (yr Gpc3)' length=3>\n",
       "  3908.209488939609\n",
       " 1952.4639435773054\n",
       " 1080.6507866022996)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rates_table[\"sim_rate_O4\"] = [1.3598513465134647e-05, 4.462124683568844e-06, 1.355987556826069e-06] * (1 / (u.Mpc**3 * u.yr))\n",
    "rates_table[\"sim_rate_O5\"] = [3.908209488939608e-06, 1.952463943577305e-06, 1.0806507866022996e-06] * (1 / (u.Mpc**3 * u.yr))\n",
    "\n",
    "\n",
    "# Conversion in Gpc^-3/ yr\n",
    "rates_table[\"sim_rate_O4\"] = rates_table[\"sim_rate_O4\"].to(u.Gpc**-3 * u.yr**-1)\n",
    "rates_table[\"sim_rate_O5\"] = rates_table[\"sim_rate_O5\"].to(u.Gpc**-3 * u.yr**-1)\n",
    "\n",
    "\n",
    "rates_table[\"sim_rate_O4\"], rates_table[\"sim_rate_O5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "93d266c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902541136\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th><th>detection_number_O4</th><th>detection_number_O5</th><th>sim_rate_O4</th><th>sim_rate_O5</th><th>mu</th><th>sigma</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th>1 / (yr Gpc3)</th><th>1 / (yr Gpc3)</th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>80.0</td><td>320.0</td><td>810.0</td><td>1482</td><td>2307</td><td>13598.513465134649</td><td>3908.209488939609</td><td>5.768320995793772</td><td>0.7037123471233048</td></tr>\n",
       "<tr><td>NSBH</td><td>61.0</td><td>130.0</td><td>242.0</td><td>2492</td><td>5441</td><td>4462.124683568845</td><td>1952.4639435773054</td><td>4.867534450455582</td><td>0.41890166985175514</td></tr>\n",
       "<tr><td>BBH</td><td>15.3</td><td>23.9</td><td>38.2</td><td>6040</td><td>21559</td><td>1355.9875568260693</td><td>1080.6507866022996</td><td>3.173878458937465</td><td>0.2781349878864127</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population  lower    mid   ...         mu               sigma       \n",
       "                           ...                                      \n",
       "   str4    float64 float64 ...      float64            float64      \n",
       "---------- ------- ------- ... ----------------- -------------------\n",
       "       BNS    80.0   320.0 ... 5.768320995793772  0.7037123471233048\n",
       "      NSBH    61.0   130.0 ... 4.867534450455582 0.41890166985175514\n",
       "       BBH    15.3    23.9 ... 3.173878458937465  0.2781349878864127"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "standard_90pct_interval, = np.diff(stats.norm.interval(0.9))\n",
    "rates_table['mu'] = np.log(rates_table['mid'])\n",
    "rates_table['sigma'] = (np.log(rates_table['upper']) - np.log(rates_table['lower'])) / standard_90pct_interval\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2c47ff81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.768321  , 4.86753445, 3.17387846]),\n",
       " array([0.70371235, 0.41890167, 0.27813499]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extract the log-normal parameters for each population as numpy arrays\n",
    "fiducial_log_rates = np.asarray(rates_table['mu'])\n",
    "fiducial_log_rate_errs = np.asarray(rates_table['sigma'])\n",
    "\n",
    "fiducial_log_rates , fiducial_log_rate_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7e19d522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=3</i>\n",
       "<table id=\"table6902541136\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>population</th><th>lower</th><th>mid</th><th>upper</th><th>detection_number_O4</th><th>detection_number_O5</th><th>sim_rate_O4</th><th>sim_rate_O5</th><th>mu</th><th>sigma</th><th>fiducial_log_rate</th><th>fiducial_log_rate_err</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th>1 / (yr Gpc3)</th><th>1 / (yr Gpc3)</th><th></th><th></th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>BNS</td><td>80.0</td><td>320.0</td><td>810.0</td><td>1482</td><td>2307</td><td>13598.513465134649</td><td>3908.209488939609</td><td>5.768320995793772</td><td>0.7037123471233048</td><td>5.768320995793772</td><td>0.7037123471233048</td></tr>\n",
       "<tr><td>NSBH</td><td>61.0</td><td>130.0</td><td>242.0</td><td>2492</td><td>5441</td><td>4462.124683568845</td><td>1952.4639435773054</td><td>4.867534450455582</td><td>0.41890166985175514</td><td>4.867534450455582</td><td>0.41890166985175514</td></tr>\n",
       "<tr><td>BBH</td><td>15.3</td><td>23.9</td><td>38.2</td><td>6040</td><td>21559</td><td>1355.9875568260693</td><td>1080.6507866022996</td><td>3.173878458937465</td><td>0.2781349878864127</td><td>3.173878458937465</td><td>0.2781349878864127</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "population  lower    mid   ... fiducial_log_rate fiducial_log_rate_err\n",
       "                           ...                                        \n",
       "   str4    float64 float64 ...      float64             float64       \n",
       "---------- ------- ------- ... ----------------- ---------------------\n",
       "       BNS    80.0   320.0 ... 5.768320995793772    0.7037123471233048\n",
       "      NSBH    61.0   130.0 ... 4.867534450455582   0.41890166985175514\n",
       "       BBH    15.3    23.9 ... 3.173878458937465    0.2781349878864127"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "rates_table['fiducial_log_rate'] = fiducial_log_rates\n",
    "rates_table['fiducial_log_rate_err'] =  fiducial_log_rate_errs\n",
    "\n",
    "rates_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f326e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prob_quantiles = np.asarray([0.05, 0.5, 0.95])\n",
    "run_duration = 1.0  # years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "40c16d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.330892345522338 34.3640927188856 111.63172036081173\n",
      "34.05143319981825 72.0894882442789 146.04995420420497\n",
      "64.03864903155096 105.93977687481468 170.6130780949588\n",
      "57.7025770477992 188.39270153379962 601.7266733340127\n",
      "179.43478574585095 361.7728800589275 723.0345185131331\n",
      "298.3272702572061 476.30088523036954 755.8459665889585\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for run_name in run_names:\n",
    "    results[run_name] = {}\n",
    "\n",
    "    for pop in ['BNS', 'NSBH', 'BBH']:\n",
    "\n",
    "        rates_row = rates_table[rates_table['population'] == pop]\n",
    "        rate = rates_row[f'sim_rate_{run_name}']  # here  rates_row['mass_fraction'] = 1\n",
    "\n",
    "        mu =  rates_row['fiducial_log_rate']  + np.log(run_duration)  + np.log(rates_row[f'detection_number_{run_name}'] / rate)\n",
    "        sigma  = rates_row['fiducial_log_rate_err']\n",
    "\n",
    "        lo, mid, hi = poisson_lognormal_rate_quantiles(prob_quantiles, mu, sigma)\n",
    "        print(  lo, mid, hi)\n",
    "        lo = int(np.floor(lo))\n",
    "        mid = int(np.round(mid))\n",
    "        hi = int(np.ceil(hi))\n",
    "\n",
    "        mid, lo, hi = format_with_errorbars(mid, lo, hi)\n",
    "        \n",
    "        results[run_name].setdefault('low', {})[pop] = lo\n",
    "        results[run_name] .setdefault('mid', {})[pop] = mid\n",
    "        results[run_name] .setdefault('high', {})[pop] = hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "342ec999",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for run_name, stats in results.items():\n",
    "    for pop in stats['mid']:\n",
    "        rows.append({\n",
    "            \"run\": run_name,\n",
    "            \"population\": pop,\n",
    "            \"low\": f\"-{stats['low'][pop]}\",\n",
    "            \"mid\": stats['mid'][pop],\n",
    "            \"high\": f\"+{stats['high'][pop]}\",\n",
    "        })\n",
    "\n",
    "results_table = Table(rows=rows, names=(\"run\", \"population\", \"low\", \"mid\", \"high\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5d25c1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=6</i>\n",
       "<table id=\"table6899940560\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>run</th><th>population</th><th>low</th><th>mid</th><th>high</th></tr></thead>\n",
       "<thead><tr><th>str2</th><th>str4</th><th>str4</th><th>str3</th><th>str4</th></tr></thead>\n",
       "<tr><td>O4</td><td>BNS</td><td>-25</td><td>34</td><td>+78</td></tr>\n",
       "<tr><td>O4</td><td>NSBH</td><td>-38</td><td>72</td><td>+75</td></tr>\n",
       "<tr><td>O4</td><td>BBH</td><td>-42</td><td>106</td><td>+65</td></tr>\n",
       "<tr><td>O5</td><td>BNS</td><td>-130</td><td>190</td><td>+410</td></tr>\n",
       "<tr><td>O5</td><td>NSBH</td><td>-180</td><td>360</td><td>+360</td></tr>\n",
       "<tr><td>O5</td><td>BBH</td><td>-180</td><td>480</td><td>+280</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=6>\n",
       "run  population low  mid  high\n",
       "str2    str4    str4 str3 str4\n",
       "---- ---------- ---- ---- ----\n",
       "  O4        BNS  -25   34  +78\n",
       "  O4       NSBH  -38   72  +75\n",
       "  O4        BBH  -42  106  +65\n",
       "  O5        BNS -130  190 +410\n",
       "  O5       NSBH -180  360 +360\n",
       "  O5        BBH -180  480 +280"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "15d54825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Observing Run  O4\n",
      "==============================\n",
      "run population low mid high\n",
      "--- ---------- --- --- ----\n",
      " O4        BNS -25  34  +78\n",
      " O4       NSBH -38  72  +75\n",
      " O4        BBH -42 106  +65\n",
      "==============================\n",
      "\n",
      " Observing Run  O5\n",
      "==============================\n",
      "run population low  mid high\n",
      "--- ---------- ---- --- ----\n",
      " O5        BNS -130 190 +410\n",
      " O5       NSBH -180 360 +360\n",
      " O5        BBH -180 480 +280\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# display by run\n",
    "for run_name in sorted(set(results_table['run'])):\n",
    "    print(f\"\\n Observing Run  {run_name}\")\n",
    "    print(\"=\" * 30)\n",
    "    print(results_table[results_table['run'] == run_name])\n",
    "    print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2946c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tilepy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
